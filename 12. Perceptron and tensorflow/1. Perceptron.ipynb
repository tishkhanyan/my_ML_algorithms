{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptron model takes the input x if the weighted sum of the inputs is greater than threshold b output will be 1 else output will be 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](perceptron1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](perceptron2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import sklearn.datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  class  \n",
       "0          0.4601                  0.11890      0  \n",
       "1          0.2750                  0.08902      0  \n",
       "2          0.3613                  0.08758      0  \n",
       "3          0.6638                  0.17300      0  \n",
       "4          0.2364                  0.07678      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the breast cancer data\n",
    "breast_cancer = sklearn.datasets.load_breast_cancer()\n",
    "\n",
    "#convert the data to pandas dataframe.\n",
    "data = pd.DataFrame(breast_cancer.data, columns = breast_cancer.feature_names)\n",
    "data[\"class\"] = breast_cancer.target\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       "count     569.000000              569.000000  ...     569.000000   \n",
       "mean        0.181162                0.062798  ...      25.677223   \n",
       "std         0.027414                0.007060  ...       6.146258   \n",
       "min         0.106000                0.049960  ...      12.020000   \n",
       "25%         0.161900                0.057700  ...      21.080000   \n",
       "50%         0.179200                0.061540  ...      25.410000   \n",
       "75%         0.195700                0.066120  ...      29.720000   \n",
       "max         0.304000                0.097440  ...      49.540000   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       worst fractal dimension       class  \n",
       "count               569.000000  569.000000  \n",
       "mean                  0.083946    0.627417  \n",
       "std                   0.018061    0.483918  \n",
       "min                   0.055040    0.000000  \n",
       "25%                   0.071460    0.000000  \n",
       "50%                   0.080040    1.000000  \n",
       "75%                   0.092080    1.000000  \n",
       "max                   0.207500    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting a graph to see class imbalance\n",
    "data['class'].value_counts().plot(kind = \"barh\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#perform scaling on the data.\n",
    "X = data.drop(\"class\", axis = 1)\n",
    "Y = data[\"class\"]\n",
    "mnscaler = MinMaxScaler()\n",
    "X = mnscaler.fit_transform(X)\n",
    "X = pd.DataFrame(X, columns=data.drop(\"class\",axis = 1).columns)\n",
    "\n",
    "#train test split.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.1, stratify = Y, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_Perceptron:\n",
    "    def __init__(self, epochs = 5000):\n",
    "        self.epochs = epochs\n",
    "#         self.lr = lr\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        self.X = X.to_numpy()\n",
    "        self.Y = Y.to_numpy()\n",
    "        \n",
    "        self.X = np.insert(self.X, 0, 1.0, axis=1)   # adding bias directly to X as a column of 1's\n",
    "        self.weights = np.random.uniform(low = -2, high = 2, size=self.X.shape[1]) # generating inital weights in range (-2, 2)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            rand_k = np.random.randint(0,self.Y.shape[0])\n",
    "            x = self.X[rand_k]\n",
    "            y_pred = 0\n",
    "            \n",
    "            if np.dot(x, self.weights) > 0:\n",
    "                y_pred = 1\n",
    "            else:\n",
    "                y_pred = 0\n",
    "            \n",
    "#             self.weights += self.lr * (self.Y[rand_k] - y_pred) * x\n",
    "            self.weights += (self.Y[rand_k] - y_pred) * x\n",
    "        pass\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        Xx_test = X_test.to_numpy()\n",
    "        Xx_test = np.insert(Xx_test, 0, 1.0, axis=1)\n",
    "        \n",
    "        Y_pred = []\n",
    "        \n",
    "        for x in Xx_test:\n",
    "            if np.dot(x, self.weights) > 0:\n",
    "                Y_pred.append(1)\n",
    "            else:\n",
    "                Y_pred.append(0)\n",
    "        return np.array(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "my_perceptron = my_Perceptron()\n",
    "my_perceptron.fit(X_train, Y_train)\n",
    "my_pred = my_perceptron.predict(X_test)\n",
    "\n",
    "accuracy_score(Y_test, my_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interestingly, here we might get different scores like 0.92, 0.96 and even 0.98 obviously depending on the choice of initial weights and randomly choosen datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "sklearn_perceptron = Perceptron(tol=1e-1, random_state=0)\n",
    "sklearn_perceptron.fit(X_train, Y_train)\n",
    "sklearn_pred = sklearn_perceptron.predict(X_test)\n",
    "\n",
    "accuracy_score(Y_test, sklearn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_perceptron = Perceptron(tol=1e-2, random_state=0)\n",
    "sklearn_perceptron.fit(X_train, Y_train)\n",
    "sklearn_pred = sklearn_perceptron.predict(X_test)\n",
    "\n",
    "accuracy_score(Y_test, sklearn_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate a logistic regression task to tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('classification.csv')\n",
    "\n",
    "y = data['default']\n",
    "\n",
    "# some preprocessing\n",
    "x1 = pd.get_dummies(data[['ed']]) \n",
    "x2 = data.drop(['ed', 'age', 'address', 'income'], axis = 1)\n",
    "\n",
    "X = pd.concat([x1, x2], axis = 1)\n",
    "X = X.drop(['ed_high school', 'ed_postgraduate'], axis = 1)\n",
    "X['add_feature_1'] = X.debtinc * X.creddebt\n",
    "X = X.drop(['default'], axis = 1)\n",
    "\n",
    "#finally, \n",
    "# y = tf.one_hot(y, depth=len(np.unique(y)))\n",
    "\n",
    "X, y = np.array(X, np.float32), np.array(y, np.float32)\n",
    "y=y.reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "input_shape = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "nr_samples = X_train.shape[0]\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (X_train, y_train)).shuffle(nr_samples).batch(batch_size)\n",
    "next(iter(train_dataset))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model, one layer just with sigmoid activation\n",
    "def get_logistic_regression_model():\n",
    "  return tf.keras.Sequential(\n",
    "      [tf.keras.layers.Dense(1,activation='sigmoid')])\n",
    "\n",
    "# defining the needed loss\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# defining the optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "# making a minibatch SGD training\n",
    "nr_epochs = 100\n",
    "losses, weights, biases = [], [], []\n",
    "logistic_regression = get_logistic_regression_model()\n",
    "for epoch in range(nr_epochs):\n",
    "  for batch_x, batch_y in train_dataset:\n",
    "    with tf.GradientTape() as tape:\n",
    "      # Compute current loss.\n",
    "      l = loss(logistic_regression(batch_x, training=True), batch_y)\n",
    "      # Calculate the gradient with respect to trainable variables (w and b).\n",
    "      grads = tape.gradient(l, logistic_regression.trainable_variables)\n",
    "      # Apply the gradient step (learning rate is part of the optimizer).\n",
    "      optimizer.apply_gradients(\n",
    "          zip(grads, logistic_regression.trainable_variables))\n",
    "  # At the end of the epoch, compute thes loss on the whole dataset.\n",
    "  losses.append(loss(logistic_regression(X), tf.convert_to_tensor(y)))\n",
    "  w, b = logistic_regression.get_weights()\n",
    "#   print(f'epoch {epoch + 1}, loss {losses[-1]:f}, w: {w}, b: {b}')\n",
    "  weights.append(w)\n",
    "  biases.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7357142857142858"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = logistic_regression(X_test)\n",
    "y_pred=np.zeros(X_test.shape[0])\n",
    "\n",
    "for i in range(len(y_proba)):\n",
    "    \n",
    "    if y_pred[i] >= 0.5:\n",
    "        y_pred[i] = 1\n",
    "    else:\n",
    "        y_pred[i] = 0\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "# as of class imbalance seems that this is not a bad result at all "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
